{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Board Game AI\n",
    "\n",
    "This notebook is used to train the AI for the board game using both Q-Learning and Deep Q-Network (DQN) with PyTorch. It enables GPU acceleration on Windows and maintains compatibility with Mac. The notebook includes visualizations for better transparency and progress tracking across multiple training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.environments.board_game_env import BoardGameEnv\n",
    "from src.agents.q_learning_agent import QLearningAgent\n",
    "from src.agents.dqn_agent import DQNAgent\n",
    "from src.utils.utils import evaluate_agent, plot_training_results, plot_version_comparison\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device (CPU or CUDA)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the environment and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game environment\n",
    "env = BoardGameEnv()\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# Create Q-Learning and DQN agents\n",
    "q_agent = QLearningAgent(state_size, action_size)\n",
    "dqn_agent = DQNAgent(state_size, action_size, device)\n",
    "\n",
    "# Set training parameters\n",
    "num_episodes = 10000\n",
    "max_steps = 100\n",
    "batch_size = 32\n",
    "update_target_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agents\n",
    "\n",
    "Run the training process for both Q-Learning and DQN agents and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(env, agent, num_episodes, max_steps, batch_size=None, update_target_every=None):\n",
    "    \"\"\"Train the agent (Q-Learning or DQN).\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (QLearningAgent or DQNAgent): The agent to train.\n",
    "        num_episodes (int): Number of episodes to train.\n",
    "        max_steps (int): Maximum steps per episode.\n",
    "        batch_size (int): Batch size for DQN training (ignored for Q-Learning).\n",
    "        update_target_every (int): Number of episodes between target network updates for DQN (ignored for Q-Learning).\n",
    "\n",
    "    Returns:\n",
    "        list: Episode rewards.\n",
    "        list: Win rates.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    win_rates = []\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for step in range(max_steps):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            if isinstance(agent, QLearningAgent):\n",
    "                agent.update_q_value(state, action, reward, next_state)\n",
    "            else:  # DQNAgent\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                if len(agent.memory) > batch_size:\n",
    "                    agent.replay(batch_size)\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "        \n",
    "        # Calculate win rate every 100 episodes\n",
    "        if episode % 100 == 0:\n",
    "            win_rate = evaluate_agent(env, agent)\n",
    "            win_rates.append(win_rate)\n",
    "\n",
    "        if isinstance(agent, DQNAgent) and episode % update_target_every == 0:\n",
    "            agent.update_target_model()\n",
    "\n",
    "    return episode_rewards, win_rates\n",
    "\n",
    "# Train Q-Learning agent\n",
    "print(\"Training Q-Learning Agent...\")\n",
    "q_rewards, q_win_rates = train_agent(env, q_agent, num_episodes, max_steps)\n",
    "\n",
    "# Train DQN agent\n",
    "print(\"\\nTraining DQN Agent...\")\n",
    "dqn_rewards, dqn_win_rates = train_agent(env, dqn_agent, num_episodes, max_steps, batch_size, update_target_every)\n",
    "\n",
    "# Plot training results\n",
    "plot_training_results(q_rewards, q_win_rates, \"Q-Learning\")\n",
    "plot_training_results(dqn_rewards, dqn_win_rates, \"DQN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_agent.save_model('q_learning_model.json')\n",
    "dqn_agent.save('dqn_model.pth')\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare agent performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_agents(env, q_agent, dqn_agent, num_games=100):\n",
    "    q_win_rate = evaluate_agent(env, q_agent, num_games)\n",
    "    dqn_win_rate = evaluate_agent(env, dqn_agent, num_games)\n",
    "    \n",
    "    print(f\"Q-Learning Agent Win Rate: {q_win_rate:.2%}\")\n",
    "    print(f\"DQN Agent Win Rate: {dqn_win_rate:.2%}\")\n",
    "    \n",
    "    plt.bar(['Q-Learning', 'DQN'], [q_win_rate, dqn_win_rate])\n",
    "    plt.title('Agent Performance Comparison')\n",
    "    plt.ylabel('Win Rate')\n",
    "    plt.show()\n",
    "\n",
    "compare_agents(env, q_agent, dqn_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play test games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_test_game(env, agent, agent_name):\n",
    "    \"\"\"Play a test game using the trained agent.\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (QLearningAgent or DQNAgent): The trained agent.\n",
    "        agent_name (str): The name of the agent (for display purposes).\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    print(f\"\\nPlaying a test game with {agent_name} agent:\")\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    env.render()\n",
    "    print(f\"Game over. Total reward: {total_reward}\")\n",
    "\n",
    "play_test_game(env, q_agent, \"Q-Learning\")\n",
    "play_test_game(env, dqn_agent, \"DQN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
