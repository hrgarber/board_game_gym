{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Board Game AI using Deep Q-Network (DQN)\n",
    "\n",
    "This notebook is used to train the AI for the board game using Deep Q-Network (DQN) with PyTorch, enabling GPU acceleration on Windows and maintaining compatibility with Mac. It includes visualizations for better transparency and progress tracking across multiple training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from board_game_env import BoardGameEnv\n",
    "from dqn_agent import DQNAgent\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device (CPU or CUDA)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the environment and agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game environment and DQN agent\n",
    "env = BoardGameEnv()\n",
    "state_size = env.board_size * env.board_size\n",
    "action_size = env.board_size * env.board_size\n",
    "agent = DQNAgent(state_size, action_size, device)\n",
    "\n",
    "# Set training parameters\n",
    "num_episodes = 10000\n",
    "max_steps = 100\n",
    "batch_size = 32\n",
    "update_target_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agent\n",
    "\n",
    "Run the training process and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn_agent(env, agent, num_episodes, max_steps, batch_size, update_target_every):\n",
    "    \"\"\"Train the DQN agent.\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (DQNAgent): The DQN agent.\n",
    "        num_episodes (int): Number of episodes to train.\n",
    "        max_steps (int): Maximum steps per episode.\n",
    "        batch_size (int): Batch size for training.\n",
    "        update_target_every (int): Number of episodes between target network updates.\n",
    "\n",
    "    Returns:\n",
    "        list: Episode rewards.\n",
    "        list: Episode lengths.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for step in range(max_steps):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "        episode_lengths.append(step + 1)\n",
    "\n",
    "        if episode % update_target_every == 0:\n",
    "            agent.update_target_model()\n",
    "\n",
    "    return episode_rewards, episode_lengths\n",
    "\n",
    "# Train the agent and collect results\n",
    "rewards, lengths = train_dqn_agent(env, agent, num_episodes, max_steps, batch_size, update_target_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(rewards, lengths):\n",
    "    \"\"\"Plot the training results.\n",
    "\n",
    "    Args:\n",
    "        rewards (list): Episode rewards.\n",
    "        lengths (list): Episode lengths.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(rewards)\n",
    "    ax1.set_title('Episode Rewards')\n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Reward')\n",
    "\n",
    "    ax2.plot(lengths)\n",
    "    ax2.set_title('Episode Lengths')\n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel('Length')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_results(rewards, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save('dqn_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play a test game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_test_game(env, agent):\n",
    "    \"\"\"Play a test game using the trained agent.\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (DQNAgent): The trained DQN agent.\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    env.render()\n",
    "    print(f\"Game over. Total reward: {total_reward}\")\n",
    "\n",
    "play_test_game(env, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}