{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Board Game AI\n",
    "\n",
    "This notebook is used to train the AI for the board game using Q-learning, with visualizations for better transparency and progress tracking across multiple training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from board_game_env import BoardGameEnv\n",
    "from q_learning_agent import QLearningAgent\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a directory for saving models if it doesn't exist\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training function\n",
    "\n",
    "This function trains the Q-learning agent and provides visualizations of the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(env, agent, num_episodes=10000, save_interval=1000, plot_interval=1000):\n",
    "    \"\"\"\n",
    "    Train the Q-learning agent and visualize the training progress.\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (QLearningAgent): The Q-learning agent to train.\n",
    "        num_episodes (int): The number of episodes to train for.\n",
    "        save_interval (int): The interval at which to save the model.\n",
    "        plot_interval (int): The interval at which to update the plot.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (trained_agent, rewards, win_rates)\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    win_rates = []\n",
    "    \n",
    "    # Create a tqdm progress bar\n",
    "    pbar = tqdm(total=num_episodes, desc=\"Training Progress\", position=0, leave=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            valid_actions = env.get_valid_actions()\n",
    "            action = agent.choose_action(state, valid_actions)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            agent.update_q_value(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "        \n",
    "        rewards.append(episode_reward)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Update training progress every 100 episodes\n",
    "        if (episode + 1) % 100 == 0:\n",
    "            win_rate = sum(rewards[-100:]) / 200 + 0.5  # Convert rewards to win rate\n",
    "            win_rates.append(win_rate)\n",
    "            agent.update_training_history(episode + 1, win_rate)\n",
    "            \n",
    "            # Update progress bar description\n",
    "            pbar.set_description(f\"Training Progress - Win Rate: {win_rate:.2f}\")\n",
    "        \n",
    "        # Plot win rate over time at specified intervals\n",
    "        if (episode + 1) % plot_interval == 0:\n",
    "            ax.clear()\n",
    "            ax.plot(range(100, len(win_rates) * 100 + 1, 100), win_rates)\n",
    "            ax.set_title(f\"AI Win Rate Over Time (Version {agent.version})\")\n",
    "            ax.set_xlabel(\"Episodes\")\n",
    "            ax.set_ylabel(\"Win Rate\")\n",
    "            plt.draw()\n",
    "            plt.pause(0.1)\n",
    "        \n",
    "        # Save the model at specified intervals\n",
    "        if (episode + 1) % save_interval == 0:\n",
    "            saved_filename = agent.save_model_with_version(\"models\")\n",
    "            print(f\"\\nModel saved as {saved_filename}\")\n",
    "    \n",
    "    # Close the progress bar\n",
    "    pbar.close()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return agent, rewards, win_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the environment and agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game environment and Q-learning agent\n",
    "env = BoardGameEnv()\n",
    "agent = QLearningAgent(state_size=env.board_size * env.board_size, action_size=env.board_size * env.board_size)\n",
    "\n",
    "# Load the latest model if available\n",
    "if agent.load_latest_model(\"models\"):\n",
    "    print(f\"Loaded model version {agent.version}\")\n",
    "else:\n",
    "    print(\"No previous model found. Starting from scratch.\")\n",
    "\n",
    "# Set the number of training episodes\n",
    "num_episodes = 10000  # You can adjust this value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agent\n",
    "\n",
    "Run the training process and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent and collect results\n",
    "trained_agent, rewards, win_rates = train_agent(env, agent, num_episodes, plot_interval=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot final training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the final win rate over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(range(100, len(win_rates) * 100 + 1, 100), win_rates)\n",
    "plt.title(f\"AI Win Rate Over Time (Version {agent.version})\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Win Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance across versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_version_comparison(directory):\n",
    "    \"\"\"\n",
    "    Plot a comparison of win rates across different model versions.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The directory containing the saved models.\n",
    "    \"\"\"\n",
    "    versions = []\n",
    "    win_rates = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(\"model_v\") and filename.endswith(\".json\"):\n",
    "            temp_agent = QLearningAgent(state_size=env.board_size * env.board_size, action_size=env.board_size * env.board_size)\n",
    "            temp_agent.load_model(os.path.join(directory, filename))\n",
    "            \n",
    "            versions.append(temp_agent.version)\n",
    "            win_rates.append(temp_agent.training_history[-1][\"win_rate\"])\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(versions, win_rates)\n",
    "    plt.title(\"Win Rate Comparison Across Model Versions\")\n",
    "    plt.xlabel(\"Model Version\")\n",
    "    plt.ylabel(\"Final Win Rate\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "# Plot version comparison\n",
    "plot_version_comparison(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play a test game\n",
    "\n",
    "Let's play a test game to see how the trained AI performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_test_game(env, agent):\n",
    "    \"\"\"\n",
    "    Play a test game using the trained agent.\n",
    "\n",
    "    Args:\n",
    "        env (BoardGameEnv): The game environment.\n",
    "        agent (QLearningAgent): The trained Q-learning agent.\n",
    "    \"\"\"\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        clear_output(wait=True)\n",
    "        display(env.get_board_image())\n",
    "        \n",
    "        valid_actions = env.get_valid_actions()\n",
    "        action = agent.choose_action(state, valid_actions)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        print(f\"AI's move: {action // env.board_size}, {action % env.board_size}\")\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    display(env.get_board_image())\n",
    "    \n",
    "    if reward == 1:\n",
    "        print(\"AI wins!\")\n",
    "    elif reward == -1:\n",
    "        print(\"AI loses!\")\n",
    "    else:\n",
    "        print(\"It's a draw!\")\n",
    "\n",
    "# Play a test game\n",
    "play_test_game(env, trained_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
